# begin
深度学习是机器学习的一个主要分支，下图是训练的过程：

![[Pasted image 20220129113628.png]]

- 1.  从一个随机初始化参数的模型开始，这个模型基本毫不“智能”。
    
- 2.  获取一些数据样本（例如，音频片段以及对应的{是,否}{是,否}标签）。
    
- 3.  调整参数，使模型在这些样本中表现得更好。
    
- 4.  重复第2步和第3步，直到模型在任务中的表现令你满意。

## 学习目的
1.  我们可以学习的_数据_（data）。
    
2.  如何转换数据的_模型_（model）。
    
3.  一个_目标函数_（objective function），用来量化模型的有效性。
    
4.  调整模型参数以优化目标函数的_算法_（algorithm）。

## 数据

  每个数据集由一个个_样本_（example, sample）组成，每个数据集由一个个_样本_（example, sample）组成，通常每个样本由一组称为_特征_（features，或_协变量_（covariates））的属性组成。 机器学习模型会根据这些属性进行预测。
  
  当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的_维数_（dimensionality）。 固定长度的特征向量是一个方便的属性，它有助于我们量化学习大量样本。


  ## 深度学习

深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为_深度学习_（deep learning）。


## 目标函数

定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，我们称之为_目标函数_（objective function）。

我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为_损失函数_（loss function，或cost function）。

这两个函数本质上是相同的，只是翻转一下符号。

通常，损失函数是根据模型参数定义的，并取决于数据集。 在一个数据集上，我们通过最小化总损失来学习模型参数的最佳值。 该数据集由一些为训练而收集的样本组成，称为_训练数据集_（training dataset，或称为_训练集_（training set））。

在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的效能，这里的“新数据集”通常称为_测试数据集_（test dataset，或称为_测试集_（test set））。

一个模型在训练集上表现良好，但不能推广到测试集时，我们说这个模型是“过拟合”（overfitting）的。

- 总结：训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。



### 应用场景

- 当任务在试图预测数值时，最常见的损失函数是_平方误差_（squared error），即预测值与实际值之差的平方。

- 当试图解决分类问题时，最常见的目标函数是最小化错误率，即预测与实际情况不符的样本比例。


## 监督学习

例子： 假设我们需要预测患者是否会心脏病发作，那么观察结果“心脏病发作”或“心脏病没有发作”将是我们的标签。 输入特征可能是生命体征，如心率、舒张压和收缩压。

目的： 是生成一个模型，能够将任何输入特征映射到标签，即预测。


## 回归

_回归_（regression）是最简单的监督学习任务之一。

当标签，是一个数值，并且标签取任意数值时，我们称之为_回归_问题。

判断回归问题的一个很好的经验法则是，任何有关“多少”的问题很可能就是回归问题。比如：

-   这个手术需要多少小时？
    
-   在未来六小时，这个镇会有多少降雨量？


## 分类

最简单的分类问题是只有两类，我们称之为“二元分类”。 例如，数据集可能由动物图像组成，标签可能是{猫,狗}{猫,狗}两类。 在回归中，我们训练一个回归函数来输出一个数值； 而在分类中，我们训练一个分类器，它的输出即为预测的类别。

当我们有两个以上的类别时，我们把这个问题称为_多元分类_（multiclass classification）问题。 常见的例子包括手写字符识别 {0,1,2,...9,a,b,c,...}{0,1,2,...9,a,b,c,...}。 与解决回归问题不同，分类问题的常见损失函数被称为_交叉熵_（cross-entropy）。




## 添加指定的conda python环境到jupyter lab



1.    
    activate 环境名称
    

3.  conda install nb_conda
    

5.  conda install ipykernel
    

7.  conda install -n 环境名称 ipykernel
    

9.  python -m ipykernel install --user --name 环境名称




效果图
![[Pasted image 20220129133602.png]]


# basic

## 广播机制
例如：`a`和`b`分别是3×13×1和1×21×2矩阵，如果让它们相加，它们的形状不匹配。 我们将两个矩阵_广播_为一个更大的3×23×2矩阵，如下所示：矩阵`a`将复制列， 矩阵`b`将复制行，然后再按元素相加。

## 运算符

常见的标准算术运算符（`+`、`-`、`*`、`/`和`**`）

![[../temp/Pasted image 20220203134448.png]]

## 节省内存
我们也可以使用`X[:] = X + Y`或`X += Y`来减少操作的内存开销。

## tensor connect
![[../temp/Pasted image 20220203134523.png]]

## 索引和切片
![[../temp/Pasted image 20220203134608.png]]

##  转换为其他Python对象
```python
A = X.numpy()
B = torch.tensor(A)
type(A), type(B)
```

-   深度学习存储和操作数据的主要接口是张量（nn维数组）。它提供了各种功能，包括基本数学运算、广播、索引、切片、内存节省和转换其他Python对象。
	


# 数据预处理

## 读取数据集
要从创建的CSV文件中加载原始数据集，我们导入`pandas`包并调用`read_csv`函数。

## 缺失值处理


```python
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]
inputs = inputs.fillna(inputs.mean()) # 对NAN缺失值用平均值进行替换插值
inputs
```

源数据：
![[../temp/Pasted image 20220203143729.png]]


插值后数据：
![[../temp/Pasted image 20220203143711.png]]

对于Alley列有Pave和NaN两种类型，需要转换为数字形式，通过pandas.get_dummies()

##  转换为张量格式
```python
import torch

X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)
X, y
```

![[../temp/Pasted image 20220203145712.png]]



# 线性神经网络

	### 线性回归
_回归_（regression）是能为一个或多个自变量与因变量之间关系建模的一类方法。 在自然科学和社会科学领域，回归经常用来表示输入和输出之间的关系。


#